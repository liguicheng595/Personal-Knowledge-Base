{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd22ef1",
   "metadata": {},
   "source": [
    "# Using TensorBoard with PyTorch\n",
    "## 环境准备\n",
    "\n",
    "在运行这个实例之前你需要安装 PyTorch, TorchVision, Matplotlib, and TensorBoard.\n",
    "\n",
    "With `conda`:\n",
    "\n",
    "`conda install pytorch torchvision -c pytorch`\n",
    "`conda install matplotlib tensorboard`\n",
    "\n",
    "With `pip`:\n",
    "\n",
    "`pip install torch torchvision matplotlib tensorboard`\n",
    "\n",
    "Once the dependencies are installed, restart this notebook in the Python environment where you installed them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c344d7",
   "metadata": {},
   "source": [
    "## 引言\n",
    "\n",
    "在本笔记中，我们将使用Fashion-MNIST数据集来训练LeNet-5的一种变体。Fashion-MNIST是一组图像瓷砖，描绘了各种衣物，带有十个类别标签，指示所描绘的衣物类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96a5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d2659",
   "metadata": {},
   "source": [
    "## 一、在TensorBoard中显示图像\n",
    "\n",
    "我们从将数据集中的样本图像添加到TensorBoard开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517484bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Store separate training and validations splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5256fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f266fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoq0lEQVR4nO3de1RVZfoH8AdULl4ARQERUbzkpdQxNGLsNsnImKWlXWwsmXLGydBC12TaZE63we5moTatpprM0WzS0pY2hoVjA6gomamoSYoi4I2LqEiwf380nJ/P92zZHDjKPvD9rMVaPufsc/Z73r3P9l37fc7zehmGYQgRERGRDXg3dgOIiIiIanBgQkRERLbBgQkRERHZBgcmREREZBscmBAREZFtcGBCREREtsGBCREREdkGByZERERkGxyYEBERkW1wYEJERES2cckGJikpKdK9e3fx8/OTmJgY2bx586XaFRERETURXpdirZzly5fLxIkTZfHixRITEyPz58+XFStWSE5OjoSEhNT62urqasnPz5d27dqJl5eXu5tGREREl4BhGFJWVibh4eHi7V3/+x6XZGASExMjQ4cOlTfffFNEfh5sdO3aVaZNmyazZs2q9bWHDx+Wrl27urtJREREdBnk5eVJREREvV/f0o1tERGR8+fPS1ZWlsyePdvxmLe3t8TFxUl6errT9hUVFVJRUeGIa8ZJzz33nPj5+bm7eURERHQJnDt3Tp588klp165dg97H7QOT48ePS1VVlYSGhqrHQ0NDZc+ePU7bJycny9NPP+30uJ+fn/j7+7u7eURERHQJNTQNo9F/lTN79mwpKSlx/OXl5TV2k4iIiKiRuP2OSceOHaVFixZSWFioHi8sLJSwsDCn7X19fcXX19fdzSAiIiIP5PY7Jj4+PhIdHS2pqamOx6qrqyU1NVViY2PdvTsiIiJqQtx+x0REZMaMGZKQkCBDhgyRa665RubPny/l5eXywAMPXIrdERERURNxSQYm99xzjxw7dkyeeuopKSgokF/84heybt06p4TY+nr44Yfd8j7UuBYuXFjr8zzOTYMnHGesmuBq8t5f/vIXFY8aNUrFffr0UXFVVZWKseZDYGCgS/u3A084zgiPQ4sWLRqpJT9ztXpHY9T6sjrO7nBJBiYiIlOnTpWpU6deqrcnIiKiJqjRf5VDREREVIMDEyIiIrKNSzaVQ0TkKVydq//pp59UfPz4cRVv375dxVifKSAgQMXdunVTsSfmmHiihuaU7NixQ8WrV69WcadOnVQ8duxYFXfs2FHFVuch5qA0NDfKrnjHhIiIiGyDAxMiIiKyDQ5MiIiIyDaYY0JNxksvvaTiu+66S8VBQUG1xvVhVXegoXO+l/r9RX5eEfRCRUVFKv7oo49U3Lt3bxWPGTOmwW243Kqrq1WMdURwSY2PP/5YxadPn1Yx1im58sora93fyZMna23fDz/8oGLMScHcBaofV3M01qxZo2KszTVlyhQVb9iwQcVvv/22im+44QYVX3vttSrGHJimkkNihXdMiIiIyDY4MCEiIiLb4MCEiIiIbIM5JmRbr776qoqvuOIKFe/evVvFy5cvVzHO52LtieLiYqd9Tpo0ScVJSUkq7tKli4obWv8CYa4Dxq5atWqVil977TWnbc6fP6/iI0eOqNjPz0/Fw4YNU/GKFStUvGTJElebedlZ9SuufePv76/igoICFWOfhISEqBjrmGCOCuYq/Pvf/1Zx165dVexq/Quqn9TUVBX36tVLxX379q319XfeeaeKv/32WxXn5+ereOfOnSoeOHCgivE4s44JERER0SXGgQkRERHZBgcmREREZBscmBAREZFtMPmVbAsLfWECIiYI9ujRQ8VYJKtlS326Y2ExEZHPP/9cxZ9++qmKMcnxscceU3H//v2d3rO2NjQUJp4uXLhQxXv37lWxr6+vZZswcROLg1VVVakYEzmzs7Mv3mAPgYWtbrzxRhXjeYHnWuvWrVWMBdXOnj1ba4xJj5gUeerUKRV36NBBxWaF+ZpKYmRDWCWL4nHCc98q2dXq/QcNGqTiffv2qRivcYcOHVIxLvZYH56QMMs7JkRERGQbHJgQERGRbXBgQkRERLbBHBOyLSxu9p///EfFmFNy4MABFeMifZhLUVFR4bTPdu3a1bpNZmamim+55RYVDx06VMUjR45UMS7aZZX38sEHH6g4IyNDxfv371dxmzZtVIyFu3x8fARhPgUWgcMCbFYLiz377LMqHj58uNM+L6e65FtkZWWpGI9DTEyMirFAW0pKiop/+9vfqhhzFzBXAHNGMJcBc0xycnJUHBsbq2I75g14gl27dqkYF9Wz4moBNFzssaSkRMWtWrVSMZ439TnOnnBu8I4JERER2QYHJkRERGQbHJgQERGRbTDHpInYsWOHinv27KlizD2oD7O5+to0dC5z69atKsaF1WbNmqXitWvXqhjn3c1yShDWLThx4oSKsV5EYGCgiv/73/+qOD09XcWYb7Fnzx4V45zzunXrVIxzzp07d1Yx9jnmQgQEBAgKDg5WMebmHD16VMXt27dXMebZYE0PT4DHDXNzsI9GjBih4tGjR6sYc5Hw/fA4Wi3uiMcNF1rEnBizejWekFvgTvWp5YLnLuacWe3D1T7G6/Rnn32m4sGDB6v4zJkzKsZ6OU2lfg3vmBAREZFtcGBCREREtsGBCREREdkGc0w81IIFC1T89ttvq/i6665T8QMPPKBirLchYj0X6epcZUPnX7GGQHx8vIrvv/9+FU+cOFHFmAeANQLMdOnSRcXR0dEqLigoUPHhw4dVjDkix44dU3F5ebmKZ86cqeKVK1eqODw8XMUdO3as9flOnTqpGOfIsSaJ2WNYUwPzk3Dee9myZSrGz4Q1Qi63upx3uGYJ9jPmhOC5bbWGCsLjgrlLqFevXir+5ptvVFxWVqZiPz8/l9rTXGHOBn5/kKt5dlawrhDWNaqsrLyk+7cr3jEhIiIi2+DAhIiIiGzD5YHJxo0b5bbbbpPw8HDx8vKSVatWqecNw5CnnnpKOnfuLP7+/hIXF+d0m5SIiIjIjMs5JuXl5TJo0CB58MEHZezYsU7Pv/jii7JgwQJ5//33JSoqSubMmSPx8fGya9cuzns2wNy5c1W8adMmFWNtCXx+48aNKjbLtxg4cKCKx40bp+I77rhDxVbz4g39/TzO83/88ccqvvXWW1UcFRWlYswLwNgMzv1jPQjMIcEY66BgLZbS0lIVY/2J48ePqxhrsVxxxRUqxjlorIeBxxn3LyJy+vRpFX/33Xcq/v3vf69irGvyySefqPhf//qXihs7x8QMrquE/X7XXXfV+nqse3L99derGM+j4uJiFYeFhak4Ly9PxVa5QwjrmmDdFRHnmjZNXV1qeuC5b1b/pTburhGCuUL4/e3Tp49b92dXLg9MRo4c6bQwWQ3DMGT+/Pny5JNPypgxY0RE5B//+IeEhobKqlWrZPz48Q1rLRERETVpbh1C5+bmSkFBgcTFxTkeCwwMlJiYGKcKmDUqKiqktLRU/REREVHz5NaBSc1PKbH8cmhoqNPPLGskJydLYGCg469r167ubBIRERF5kEavYzJ79myZMWOGIy4tLW2SgxNXa3q88847Kn7llVdUjDU8cG4S57RxftlszhrzIz788EMVL168WMVW+RdvvfWW0z4aAufx8f0xXwPvvvXu3VvFZrkP33//vYoxjwbXpsC1ciIjI1WMeVXffvutirds2eLUhgvhZ8jOzlYx5pTgeXb27FkVm61jg9vguTFgwAAV43oemN/kCZYsWaJirENidQ1avXq1irG2C/Yp5rBg7RhX8+/atm2r4qqqKhX/+OOPTq/p0aOHS/vwdHXJ/8DvS13y0Gp7fUNzTvAahu1xd60pu3LrHZOahC68+BUWFjole9Xw9fWVgIAA9UdERETNk1sHJlFRURIWFiapqamOx0pLSyUzM9Pp1wVEREREyOWpnNOnT8v+/fsdcW5urmRnZ0uHDh0kMjJSkpKS5LnnnpPevXs7fi4cHh4ut99+uzvbTURERE2QywOTrVu3yq9+9StHXJMfkpCQIO+9957MnDlTysvLZfLkyVJcXCzXXXedrFu3rtnXMLGa+7v77rtVfOjQIRVjTsnevXtVfPLkSRXj3Cfmj0RERDi1AfMlcJ4cPwPWXigqKlIxznu3aNHCaZ+ueOSRR1Q8b948FWNNAtw/rkuB+SAizmtnYB0B3IdVH+Drcb2f119/XcVPPPGEivG4Yd0SXNcGp1HxGJodA8ybweR17BPMX5gzZ47Te9rJ/PnznR7D3B1cEwnPHZSbm6vibt261fr+mAOGxxHrnuCaSpgjhr9y/MMf/qDiPXv2OLW5qeWYuCO/A/vVLAertn1YXWddbROuvYW5S6g++/OEPBSXByY33XRTrQsJeXl5yTPPPCPPPPNMgxpGREREzU/zKgVIREREtsaBCREREdlGo9cxaSpwrg/nLnFOGae6MHfhlltuUTHOWVv93r5lS31occ4a2yPivDYN5kdgHkubNm1UjLkIOF+L639Y2bFjR63xypUrVTxkyBAVY54A1o4wm2vFfAusE4KfEZ04cULFmOOB5wXmEuGimMuXL1dx//79VYzHCHMZkFnuhL+/v4qxdktFRYWKsfbKwoULa91nY0tKSnJ6DI8rrg+E+Uc4fY19gu+HNX7wvMHvEn738HmsqzJp0iQV9+zZs9a4KXJHTQ/MqzOr/+LKPlzN36hPLuCFmur6R03zUxEREZFH4sCEiIiIbIMDEyIiIrKNZplj4u71DUSs5/qwPsXmzZtV3KdPHxW///77KsZ8DtwffgbMScHcCbNFFTFvxSq/wirHZMyYMSq2WhcGYQ7J3Llza90e177B5Q0wxwXzAEScPwPmX2BuDvYR5nDgujNYt2To0KEq/vzzz1WM9TKwDgnmDuExxO3NzlPcBvOTdu7cqeLRo0erODg42Ok97Q4/o1W9iH379qkYzy3MX+rSpYuKDxw44FJ7MPcIc0xw3afmyGqdKLPrOvYzft9zcnLc1LqfWeUeYk4L5qRhfRu8vuDaOmY5ZFi/yRNqivGOCREREdkGByZERERkGxyYEBERkW00iRwTnFt0df0Cs3l3fA9Xfy8+c+ZMFWP+Q+fOnVWcn5+vYpyjxvoUmN+BdVAwtwE/D24v4jzfifPmOJ+J87WYq4Cf2ax2ijthTQJsP8ZmMKfk+PHjKsZzCed08dwy6+cLjRgxQsU4b56dna1inC/Gehp4nLF9+P4iznVLQkJCVPzDDz+o2NMW5MRjJuL8fbbKBcA1kLDPXK3Zg3VK8NzE75arzJYN8YQ1Ulyxfv16FeMxatu2rdNr8LqZkZGhYqwn88EHH6gYr8vFxcUqxvMIv29WeXlW+8fn8fpy5MgRQVjTZvz48U7b2A3vmBAREZFtcGBCREREtsGBCREREdmGR+aYWM0H1yWHxAq+B87ZpqSkqHjNmjUqxrnDAQMGqPjYsWO17g9zRHBuEuegMdcA61vg7+ODgoIEYe0T7OewsDAV43oimGOC9S1wXRcrrs6z47z+qVOnan0/s/wPV2sjYIz7wPoViYmJKsbcIaxbYpUzYpULhTEeIxHncwe3wVoKdcnVsRN3rCeCdUUwRwRrQ2BezuHDh2vdHnPMMJ/LyqWozWR3WJupV69eKjY71/HcxXowmJeCOR14fcBrnFXuEtZOwhw2rKeD74fnDf4/0a1bN0F47noC3jEhIiIi2+DAhIiIiGyDAxMiIiKyDQ5MiIiIyDY8MvnVKpkNE8kwcRQTDs2K0mDy2tNPP61iTJzERFAsxIPFf7ANmJyKiZu4P6vEUEx+w8JhuD8R52Sy/v37qxgTrzDhDheQw2RXTMi1EhERoWIs0Ib769evn4qxeBK2x2wxK+xn7DdMPsWCZ9jvmICHyWq4uGNeXp6KsWgcnjdWyXZ1gQl5eO7jZ8LPjMwWErM7q2sK9hFeUxAukonfV0woxj7FcxUTlM0WoGxu8FzHPsIieCLWidv4owW8xuE1w6rAodX1AK8vBw8eVDEWO8Tt8RqISdkizp/JE/COCREREdkGByZERERkGxyYEBERkW14ZI4JLg63fPlyFWNBGZzzxvlhs2JEOHcXHx+vYpzrs1qECwvp4D6xTRjjXKbVgnj4PBYGMivgdNVVV6k4NDRUxZh/gXO8OH86cODAWl9vBYvAYd4Nzr92795dxRs3blQx5me0b9/eaZ+uLlxotWgX5pT8/e9/VzH2GeYOBAQEqBjPZat8DjyPzRZ3wzbgPDrmS5gtjtbUWX3fMCcEc1bM8h1q2x6Pmyfm7VxqeE3EfCyzcx23waKSmAeH2+OiffjdscrxwusJfpfwPMHvP54n2AdmeXNmhebsjndMiIiIyDY4MCEiIiLb4MCEiIiIbMMjc0x69uyp4j/+8Y8q3r9/v4q3bNmi4r1796rYLN8C53hxjhnnJjG3AOf+sG4Ibo/vj6/H/Az8bbqri8+Zzb9i/RfMi8G8GqvaDzgf62qOydVXX63izMxMFd922221br9kyZJa24O1ZkScjzseB8wxwX60WrQL82Kwj61yWLDPrRb1w+fN5ptxn7iQ2Jdfflnr9s0BXiOwH/H7iOcR1gjCXAY8zq7mEjVHeM3EfA2z+h14XLCeDOaE4XXe1e+b1TUS24g5JnheWOX14ecT8cwFHXnHhIiIiGzDpYFJcnKyDB06VNq1aychISFy++23S05Ojtrm3LlzkpiYKMHBwdK2bVsZN26cFBYWurXRRERE1DS5NDBJS0uTxMREycjIkPXr10tlZaWMGDFC3ZacPn26rF69WlasWCFpaWmSn58vY8eOdXvDiYiIqOlxabJ43bp1Kn7vvfckJCREsrKy5IYbbpCSkhJ55513ZOnSpXLzzTeLiMi7774r/fr1k4yMDLn22mvd0micx8P6FZiDUtOWGjivv3v3bqd9pKenqxjvDO3bt0/FOBdptYYCzg3i3CLOSeNnxLlEqxjzAjAnRcT5N/v4HvgaXN8Dc1DwTpnZ/GdtunbtquLk5GQVY47JoEGDVGw152y2do/VXD/Oa+N7YoznAdZJwfMCX29Wl+BCVjUK6pJj8uOPP6p427ZtKsb8CpyHbw6s8qPwuOK5h99nPM+s8nbMcsKaG/wuYWyV/2G2DV7TMA8Nr3G4vVWdIIwx58Tq+2+1Fhcy+35b5S/acd2lBuWY1BQVqvlPNSsrSyorKyUuLs6xTd++fSUyMtLpP3oiIiIiVO/0+urqaklKSpJhw4Y5KoYWFBSIj4+PU8XO0NBQp+qRNSoqKtQIDu88EBERUfNR7zsmiYmJsnPnTlm2bFmDGpCcnCyBgYGOP7x9T0RERM1Hve6YTJ06VdasWSMbN26UiIgIx+NhYWFy/vx5KS4uVndNCgsLJSwszPS9Zs+eLTNmzHDEpaWlloMTnHc/ePCginHODO/gdOzYUcWYg3Kxxy6Ec8Q4x4zPW+WY4Nwjzjlb/R7ejqx+g5+RkeHS+w0YMEDFeXl5Ku7Vq5eK8TzBtXKOHj3qtA88d3BOF+eocb4W56Axtppjxno3DV3nwqqejYjzZzhx4oSKsZ+tvp+eUDehLv1yIcyfwrl/rAFkVY8C89qGDx+uYjzurtYxMcuv8ITjUhu8XuB3pS51THDtGTzXreoI4T6tvs+uPo85K/i8VT0qs+OO32/MGfP4HBPDMGTq1KmycuVK2bBhg0RFRanno6OjpVWrVpKamup4LCcnRw4dOiSxsbGm7+nr6ysBAQHqj4iIiJonl+6YJCYmytKlS+XTTz+Vdu3aOfJGAgMDxd/fXwIDA2XSpEkyY8YM6dChgwQEBMi0adMkNjbWbb/IISIioqbLpYHJokWLRETkpptuUo+/++678rvf/U5ERF577TXx9vaWcePGSUVFhcTHx8vChQvd0lgiIiJq2lwamNTlt/R+fn6SkpIiKSkp9W6UlTZt2qgYp5QwlwB/m47zhvg7bxHnuT6s8YFzfRhb5ZBYrbGAbcLtrXJarNZ0MctZsVqXxer4Yz4FfiarmhxWpkyZouL77rtPxbg2Tnh4uIoxF6moqMhpH5hLgMfdao0j/Myuzglb5RLg/vE8w/3hMcX5ZhGR9u3bqxjn5iMjI1VsVY/G03MZzGC/Yy0k7Ff87mAOSp8+fWrdH9YAcrWOSVM8Bps2bVLxsGHDVIzHwOw8xeOGa+VgDgm+B+axmP3fcSGr/yes1trC8wifR2bXD6s8GbzG2YHnZVQSERFRk8WBCREREdkGByZERERkG/Wu/GonOG+HPznGGOeLzebdcRvM6cDfgiOrOiTYZlfXRLB6f8znqEuuAe7T1flNq/V6XP0pOB4D/MyTJ09W8ddff63i6OhoFeMaMGY1QnBNFMxTwfylmmUZaljNGeNxxhjnf63qomCf4HHHOXCz88oqv+nKK690es2FXK0J4on27t2r4u3bt6sYa+hgHRPM2xk1apSK8bzCY4DnRXO0efNmFWMfYi4h1q8SEdm6dauKp02bpmL8LqxatUrFeD04duyYiq3W1rGqZ4Xw+oHvh981szWX8Dpudu23G94xISIiItvgwISIiIhsgwMTIiIiso0mkWPiKpyHM5uXa+pwLtSOrNatuOGGG1SMa2nk5uaqGGuUmNVVwfoSOIeL68ZY5Vfg8+Xl5SrGPBz8jJibgHUUcHvMkcH2mH1mnHPGefPrr7/e6TW1taGh6/vYAeaQtW7dWsW4Cjo+j+cuHjfMh8Dchk6dOqnYbN2XCzXFvB7M38I+xzyeU6dOqdjsuh4aGqpiPHfxOOH2mK+B57pVnSKrNdSQ1XXaKu9PpG45lXbDOyZERERkGxyYEBERkW1wYEJERES20fySK8hjWc2j4wrWV1xxhYqxhoHZ/C3maHzzzTcqxno2mLeCrNbO6dy5s4qDg4NVjPUssDaDVY4KMnse581PnDihYlwrpymwOpdw7h+PM87TY64B1uzBHBFcswXzITAXqTnWMcE+SEhIUDH2qVU9HhHn7zceZzxueNzxOFjliLhahwRjvN5YrcmG7y/ifI3Amjl2xDsmREREZBscmBAREZFtcGBCREREtsEcE/IYrtZqOHnypIoxp8RsDvrAgQMqxpwPnNfGOWic88W6IZjPgfUscA4c55it5rit5qB9fX3Fyq233qrinj171ro9fiZP4Gr9GcxfwM+MOSJt2rRRMZ43eNwR5hJhvkVzgDVF8FzGWjNWNYNEnK8BmD8VGBioYqydYvX9qUvOx4XwvLHKObFavwzPUxHnaxDrmBARERG5gAMTIiIisg0OTIiIiMg2ODAhIiIi22DyK3kMqwWyMDEME8cw6cusOBomu4WFhakYk2Fxe0xyxOJGR44cUXFUVJSKn332WRVjMST8DJjMh0mX2H6MRZwL0eGCdFY8cQE5qzZbFVDD44rnHiZR7t+/X8VdunRRsdVijc1xodFXXnlFxdnZ2SrG5FZcYNPsGGO/vvzyyyrG47xnzx4VY8It7gOPEyajYjI7JuDj85jc6mrBNhGRXbt2qXjo0KFO29gN75gQERGRbXBgQkRERLbBgQkRERHZRvObuCSP5Wouw5tvvqlizBs4evSo02twAbudO3eqODc3V8UlJSUqxnlvnNPGxdvGjx+v4ltuucWpTY3NqhiZJ8K5eswRwXMDjzPmDuBcf0FBgYozMzNVjDkm+HrMPcD9Nwdjx45VMRZMXLdunYox7yckJMTpPfH7vW/fPhXj9xXPAyywhvkamCOCxc0wrw3zufAzYIw5LJhjZpaLhAUTBw0a5LSN3fCOCREREdkGByZERERkGxyYEBERkW0wx4Q8lqu5Djg/3L17d6dt8LHo6GhXm9XkNIWcEldhHZJOnTqpuEePHrXG8fHxKi4qKlLxPffcU+vzhw8fVjHWp2kOMBfijTfeUDH20bFjx1SMtWFEnBfBxJwQzAHB52+88UYVYw4JuQfvmBAREZFtuDQwWbRokQwcOFACAgIkICBAYmNjZe3atY7nz507J4mJiRIcHCxt27aVcePGSWFhodsbTURERE2TSwOTiIgImTdvnmRlZcnWrVvl5ptvljFjxsj3338vIiLTp0+X1atXy4oVKyQtLU3y8/OdfvJFREREdDFeBhYpcFGHDh3kpZdekjvvvFM6deokS5culTvvvFNEfl5noF+/fpKeni7XXnttnd6vtLRUAgMD5eWXXzZdy4SIiIjs5+zZs/KnP/1JSkpKJCAgoN7vU+8ck6qqKlm2bJmUl5dLbGysZGVlSWVlpcTFxTm26du3r0RGRkp6evpF36eiokJKS0vVHxERETVPLg9MvvvuO2nbtq34+vrKQw89JCtXrpT+/ftLQUGB+Pj4SFBQkNo+NDTUqQrihZKTkyUwMNDx17VrV5c/BBERETUNLg9M+vTpI9nZ2ZKZmSlTpkyRhIQEp2WVXTF79mwpKSlx/OHS1URERNR8uFzHxMfHR3r16iUiP9d42LJli7z++utyzz33yPnz56W4uFjdNSksLJSwsLCLvp+vr69TfQkiIiJqnhpcx6S6uloqKiokOjpaWrVqJampqY7ncnJy5NChQxIbG9vQ3RAREVEz4NIdk9mzZ8vIkSMlMjJSysrKZOnSpfL111/LF198IYGBgTJp0iSZMWOGdOjQQQICAmTatGkSGxtb51/kEBERUfPm0sCkqKhIJk6cKEePHpXAwEAZOHCgfPHFF/LrX/9aRERee+018fb2lnHjxklFRYXEx8fLwoULXWpQza+Xz50759LriIiIqPHU/L/dwCokDa9j4m6HDx/mL3OIiIg8VF5enkRERNT79bYbmFRXV0t+fr4YhiGRkZGSl5fXoEItzV1paal07dqV/dgA7MOGYx+6B/ux4diHDXexPjQMQ8rKyiQ8PFy8veufwmq71YW9vb0lIiLCUWitZl0eahj2Y8OxDxuOfege7MeGYx82nFkf4src9cHVhYmIiMg2ODAhIiIi27DtwMTX11fmzp3L4msNxH5sOPZhw7EP3YP92HDsw4a71H1ou+RXIiIiar5se8eEiIiImh8OTIiIiMg2ODAhIiIi2+DAhIiIiGzDtgOTlJQU6d69u/j5+UlMTIxs3ry5sZtkW8nJyTJ06FBp166dhISEyO233y45OTlqm3PnzkliYqIEBwdL27ZtZdy4cVJYWNhILba/efPmiZeXlyQlJTkeYx/WzZEjR+S+++6T4OBg8ff3lwEDBsjWrVsdzxuGIU899ZR07txZ/P39JS4uTvbt29eILbaXqqoqmTNnjkRFRYm/v7/07NlTnn32WbX+CPtQ27hxo9x2220SHh4uXl5esmrVKvV8Xfrr5MmTMmHCBAkICJCgoCCZNGmSnD59+jJ+isZXWz9WVlbK448/LgMGDJA2bdpIeHi4TJw4UfLz89V7uKMfbTkwWb58ucyYMUPmzp0r27Ztk0GDBkl8fLwUFRU1dtNsKS0tTRITEyUjI0PWr18vlZWVMmLECCkvL3dsM336dFm9erWsWLFC0tLSJD8/X8aOHduIrbavLVu2yFtvvSUDBw5Uj7MPrZ06dUqGDRsmrVq1krVr18quXbvklVdekfbt2zu2efHFF2XBggWyePFiyczMlDZt2kh8fDwX7vyfF154QRYtWiRvvvmm7N69W1544QV58cUX5Y033nBswz7UysvLZdCgQZKSkmL6fF36a8KECfL999/L+vXrZc2aNbJx40aZPHny5foItlBbP545c0a2bdsmc+bMkW3btsknn3wiOTk5Mnr0aLWdW/rRsKFrrrnGSExMdMRVVVVGeHi4kZyc3Iit8hxFRUWGiBhpaWmGYRhGcXGx0apVK2PFihWObXbv3m2IiJGent5YzbSlsrIyo3fv3sb69euNG2+80Xj00UcNw2Af1tXjjz9uXHfddRd9vrq62ggLCzNeeuklx2PFxcWGr6+v8c9//vNyNNH2Ro0aZTz44IPqsbFjxxoTJkwwDIN9aEVEjJUrVzriuvTXrl27DBExtmzZ4thm7dq1hpeXl3HkyJHL1nY7wX40s3nzZkNEjIMHDxqG4b5+tN0dk/Pnz0tWVpbExcU5HvP29pa4uDhJT09vxJZ5jpKSEhER6dChg4iIZGVlSWVlperTvn37SmRkJPsUJCYmyqhRo1RfibAP6+qzzz6TIUOGyF133SUhISEyePBgefvttx3P5+bmSkFBgerHwMBAiYmJYT/+zy9/+UtJTU2VvXv3iojIt99+K5s2bZKRI0eKCPvQVXXpr/T0dAkKCpIhQ4Y4tomLixNvb2/JzMy87G32FCUlJeLl5SVBQUEi4r5+tN0ifsePH5eqqioJDQ1Vj4eGhsqePXsaqVWeo7q6WpKSkmTYsGFy1VVXiYhIQUGB+Pj4OE6eGqGhoVJQUNAIrbSnZcuWybZt22TLli1Oz7EP6+bAgQOyaNEimTFjhjzxxBOyZcsWeeSRR8THx0cSEhIcfWX2/WY//mzWrFlSWloqffv2lRYtWkhVVZU8//zzMmHCBBER9qGL6tJfBQUFEhISop5v2bKldOjQgX16EefOnZPHH39c7r33XsdCfu7qR9sNTKhhEhMTZefOnbJp06bGbopHycvLk0cffVTWr18vfn5+jd0cj1VdXS1DhgyRv/71ryIiMnjwYNm5c6csXrxYEhISGrl1nuGjjz6SDz/8UJYuXSpXXnmlZGdnS1JSkoSHh7MPyRYqKyvl7rvvFsMwZNGiRW5/f9tN5XTs2FFatGjh9GuHwsJCCQsLa6RWeYapU6fKmjVr5KuvvpKIiAjH42FhYXL+/HkpLi5W27NP/19WVpYUFRXJ1VdfLS1btpSWLVtKWlqaLFiwQFq2bCmhoaHswzro3Lmz9O/fXz3Wr18/OXTokIiIo6/4/b64xx57TGbNmiXjx4+XAQMGyP333y/Tp0+X5ORkEWEfuqou/RUWFub044qffvpJTp48yT4FNYOSgwcPyvr16x13S0Tc14+2G5j4+PhIdHS0pKamOh6rrq6W1NRUiY2NbcSW2ZdhGDJ16lRZuXKlbNiwQaKiotTz0dHR0qpVK9WnOTk5cujQIfbp/wwfPly+++47yc7OdvwNGTJEJkyY4Pg3+9DasGHDnH6qvnfvXunWrZuIiERFRUlYWJjqx9LSUsnMzGQ//s+ZM2fE21tfmlu0aCHV1dUiwj50VV36KzY2VoqLiyUrK8uxzYYNG6S6ulpiYmIue5vtqmZQsm/fPvnyyy8lODhYPe+2fqxHsu4lt2zZMsPX19d47733jF27dhmTJ082goKCjIKCgsZumi1NmTLFCAwMNL7++mvj6NGjjr8zZ844tnnooYeMyMhIY8OGDcbWrVuN2NhYIzY2thFbbX8X/irHMNiHdbF582ajZcuWxvPPP2/s27fP+PDDD43WrVsbS5YscWwzb948IygoyPj000+NHTt2GGPGjDGioqKMs2fPNmLL7SMhIcHo0qWLsWbNGiM3N9f45JNPjI4dOxozZ850bMM+1MrKyozt27cb27dvN0TEePXVV43t27c7fi1Sl/76zW9+YwwePNjIzMw0Nm3aZPTu3du49957G+sjNYra+vH8+fPG6NGjjYiICCM7O1v9X1NRUeF4D3f0oy0HJoZhGG+88YYRGRlp+Pj4GNdcc42RkZHR2E2yLREx/Xv33Xcd25w9e9Z4+OGHjfbt2xutW7c27rjjDuPo0aON12gPgAMT9mHdrF692rjqqqsMX19fo2/fvsbf/vY39Xx1dbUxZ84cIzQ01PD19TWGDx9u5OTkNFJr7ae0tNR49NFHjcjISMPPz8/o0aOH8ec//1ld/NmH2ldffWV6DUxISDAMo279deLECePee+812rZtawQEBBgPPPCAUVZW1gifpvHU1o+5ubkX/b/mq6++cryHO/rRyzAuKCdIRERE1Ihsl2NCREREzRcHJkRERGQbHJgQERGRbXBgQkRERLbBgQkRERHZBgcmREREZBscmBAREZFtcGBCREREtsGBCREREdkGByZERERkGxyYEBERkW1wYEJERES28X/HddLsFW1d1QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract a batch of 4 images\n",
    "images, labels = next(iter(training_loader))\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32ffa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5e94434935e0e0e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5e94434935e0e0e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 实例化，输入存储的路径\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_3')\n",
    "\n",
    "\n",
    "# 将img_grid添加到里面\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/fashion_mnist_experiment_3\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a679039",
   "metadata": {},
   "source": [
    "如果你在命令行启动TensorBoard，并在新的浏览器标签页中打开它（通常位于[localhost:6006]），你应该能在IMAGES标签下看到图像网格。\n",
    "\n",
    "## 二、用标量绘图以可视化训练和显示模型中权重和梯度变化\n",
    "\n",
    "TensorBoard对于追踪你的训练进度和效果非常有用。下面，我们将运行一个训练循环，跟踪一些指标，并保存供TensorBoard使用的数据。\n",
    "\n",
    "让我们定义一个模型来对我们的图像瓷砖进行分类，以及用于训练的优化器和损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd912e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b483d1",
   "metadata": {},
   "source": [
    "下面用定义好的网络训练一轮，看下训练损失和验证损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92215d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Batch 1000\n",
      "Batch 2000\n",
      "Batch 3000\n",
      "Batch 4000\n",
      "Batch 5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m running_vloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     20\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# Don't need to track gradents for validation\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, vdata \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(validation_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     22\u001b[0m     vinputs, vlabels \u001b[38;5;241m=\u001b[39m vdata\n\u001b[0;32m     23\u001b[0m     voutputs \u001b[38;5;241m=\u001b[39m net(vinputs)\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\multiprocessing\\queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mD:\\Software\\anaconda3\\envs\\jupyter\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(validation_loader))\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # Every 1000 mini-batches...\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "            \n",
    "            net.train(False) # Don't need to track gradents for validation\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Turn gradients back on for training\n",
    "            for name, param in net.named_parameters():\n",
    "                writer.add_histogram(f'{name}.weight', param, epoch * len(training_loader) + i)\n",
    "                writer.add_histogram(f'{name}.grad', param.grad, epoch * len(training_loader) + i)\n",
    "        \n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "            \n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3294f",
   "metadata": {},
   "source": [
    "切换到你已打开的TensorBoard并查看SCALARS、DISTRIBUTIONS、HISTOGRAMS标签页。\n",
    "\n",
    "## 三、可视化你的模型\n",
    "TensorBoard 还可以用来检查模型内部的数据流。要做到这一点，使用 `add_graph()` 方法，传入你的模型和样本输入。当你打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "images, labels = next(iter(training_loader))\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64db84",
   "metadata": {},
   "source": [
    "当你切换到TensorBoard时，你应该能看到一个GRAPHS标签。双击“NET”节点以查看模型内的层和数据流。\n",
    "\n",
    "## 四、利用嵌入(Embeddings)可视化你的数据集\n",
    "\n",
    "我们正在使用的28x28图像瓷砖可以被建模为784维向量（28 * 28 = 784）。将此投影到较低维度表示可能会很有启发性。`add_embedding()`方法会将一组数据投影到方差最高的三个维度上，并将其显示为一个交互式的3D图表。`add_embedding()`方法通过自动投影到方差最高的三个维度上来实现这一点。\n",
    "\n",
    "下面，我们将从数据集中抽取样本，并生成这样的嵌入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subset of data and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subset of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe8f30",
   "metadata": {},
   "source": [
    "现在如果你切换到TensorBoard并选择PROJECTOR标签，你应该能够看到投影的3D表示。你可以旋转和缩放模型。在大尺度和小尺度下检查它，看看是否能在投影数据和标签的聚类中发现模式。\n",
    "\n",
    "**注释：**为了获得更好的可视性，建议你：\n",
    "* 从左侧的“Color by”下拉菜单中选择“label”\n",
    "* 在顶部切换夜间模式图标，将浅色图像置于深色背景之上。\n",
    "\n",
    "### 其他资源\n",
    "\n",
    "想要了解更多详情，可以查阅：\n",
    "* [PyTorch文档关于`torch.utils.tensorboard.SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter)于[PyTorch.org](https://pytorch.org)\n",
    "* [PyTorch.org教程](https://pytorch.org/tutorials/)中的Tensorboard教程内容\n",
    "* 关于TensorBoard的更多信息，请参阅[TensorBoard文档](https://www.tensorflow.org/tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fd2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9bc8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter] *",
   "language": "python",
   "name": "conda-env-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
