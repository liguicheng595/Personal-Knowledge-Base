{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873cb3a7",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "本部分讲解Pytroch的核心数据结构tensor，了解tensor的构成，属性，运算等内容。\n",
    "\n",
    "## 一.  Tensor初认识\n",
    "Tensor 中文被翻译为张量。张量在不同学科中有不同的意义，在深度学习中张量表示的是一个多维数组，它是标量、向量、矩阵的拓展。标量是零维张量，向量是一维张量，矩阵是二维张量，一个RGB图像的数组就是一个三维张量，第一维是图像的高，第二维是图像的宽，第三维是图像的颜色通道。\n",
    "\n",
    "在pytorch中，有两个张量的相关概念极其容易混淆，分别是`torch.Tensor`和`torch.tensor`。其实，通过命名规范，可知道`torch.Tensor`是Python的一个类, `torch.tensor`是Python的一个函数。通常我们调用`torch.tensor`进行创建张量，而不直接调用`torch.Tensor`类进行创建。为了进一步区分两者，我们来看看它们代码实现。\n",
    "\n",
    "**torch.Tensor**：类定义与`torch/_tensor.py#L80`，它继承`torch._C._TensorBase`，这里看到_C就知道要接触C++代码了。\n",
    "\n",
    "<img src=\"https://tingsongyu.github.io/PyTorch-Tutorial-2nd/chapter-2/imgs/Tensor.png\" width=\"400\" /> \n",
    "\n",
    "跳转到torch/C/\\_init__.pyi #L839 可以看到：\n",
    "``` python\n",
    "# Defined in torch/csrc/autograd/python_variable.cpp\n",
    "class _TensorBase(metaclass=_TensorMeta):\n",
    "    requires_grad: _bool\n",
    "    shape: Size\n",
    "```\n",
    "张量的定义和底层C++实现是在python_variable.cpp代码中。\n",
    "\n",
    "**torch.tensor**：pytorch的一个函数，用于将数据变为张量形式的数据，例如list, tuple, NumPy ndarray, scalar等。\n",
    "\n",
    "同样，`torch.tensor`的底层实现也是[C++代码](https://github.com/pytorch/pytorch/tree/master/torch/csrc/autograd)，具体实现位于`torch_C_VariableFunctions.pyi`文件。如2.1节所述，.pyi文件用于Python类型检查，而其底层实现在对应的C++代码中。\n",
    "\n",
    "**推荐用法:**\n",
    "- 如果你需要从现有数据创建张量，使用 torch.tensor。\n",
    "- 如果你需要创建一个张量，但尚不想初始化其内容（例如，预分配张量并稍后填充），可以考虑使用其他初始化函数，如 torch.zeros, torch.ones, 或 torch.empty。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3d43d",
   "metadata": {},
   "source": [
    "## 二.Tensor的作用\n",
    "tensor之于pytorch等同于ndarray之于numpy，它是pytorch中最核心的数据结构，用于表达各类数据，如输入数据、模型的参数、模型的特征图、模型的输出等。**这里边有一个很重要的数据，就是模型的参数**。对于模型的参数，我们需要更新它们，而更新操作需要记录梯度，梯度的记录功能正是被张量所实现的（求梯度是autograd实现的）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b724a06",
   "metadata": {},
   "source": [
    "## 三. Tensor的属性\n",
    "\n",
    "如下图可知，共有data, dtype，shape, grad, grad_fn, requires_grad, is_leaf, device共八大主要属性。\n",
    "![tensor的结构](https://tingsongyu.github.io/PyTorch-Tutorial-2nd/chapter-2/imgs/tensor-arch.png)\n",
    "\n",
    "\n",
    "- data：多维数组，最核心的属性，其他属性都是为其服务的;\n",
    "\n",
    "- dtype：多维数组的数据类型，tensor数据类型如下，常用到的三种已经用红框标注出来；\n",
    "\n",
    "- shape：多维数组的形状;\n",
    "\n",
    "- device: tensor所在的设备，cpu或cuda;\n",
    "\n",
    "- grad，grad_fn，is_leaf和requires_grad就与Variable一样，**都是梯度计算中所用到的**。\n",
    "\n",
    "张量的属性还有很多，大家可以通过Pycharm的debug功能进行查看\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8da15d",
   "metadata": {},
   "source": [
    "## 四. Tensor的相关函数\n",
    "\n",
    "接下来开始学习各类张量的api，主要参考[官方文档](https://pytorch.org/docs/stable/torch.html)，通过右边目录栏可以看出有以下几个部分。\n",
    "- torchTensors\n",
    "- Generators\n",
    "- Random sampling\n",
    "- Serialization\n",
    "- Parallelism\n",
    "- Locally disabling gradient computation\n",
    "- Math operations\n",
    "- Utilities\n",
    "\n",
    "里面有上百个函数，这里只挑高频使用的进行讲解，建议大家自行浏览一遍官方文档，看看都有哪些功能，便于今后使用到的时候不必重复造轮子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12611e1",
   "metadata": {},
   "source": [
    "### 4.1 数据类型\n",
    "\n",
    "以下是常用的torch数据类型：\n",
    "\n",
    "|   Data type   |      dtype     |\n",
    "|:---------------|-------------------|\n",
    "|   32位浮点型      | `torch.float32` or `torch.float`|\n",
    "|   64位浮点型      | `torch.float64` or `torch.double`|\n",
    "|   16位浮点型      | `torch.float16` or `torch.half`|\n",
    "|   32位虚数       | `torch.complex32 ` or `torch.chalf`|\n",
    "|   8位整型（有符号） | `torch.int8 `|\n",
    "|   16位整型（有符号  | `torch.int16 ` or `torch.short`|\n",
    "|   32位整型（有符号）| `torch.int32 ` or `torch.int`|\n",
    "|   64位整型 （有符号）| `torch.int64 ` or `torch.long`|\n",
    "|   布尔值          | `torch.bool `|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6abec",
   "metadata": {},
   "source": [
    "### 4.2 张量的创建\n",
    "### 4.2.1 直接创建\n",
    "\n",
    "**torch.tensor**\n",
    "`torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)`\n",
    "   - data(arry_like)- tensor的初始数据，可以是list,tuple, numpy array, scalar或其他类型\n",
    "   - dtype(torch.dtype, optional) - tensor的数据类型，如torch.uint8, torch.float, torch.long等\n",
    "   - device (torch.device, optional) – 决定tensor位于cpu还是gpu。如果为None，将会采用默认值，默认值在torch.set_default_tensor_type()中设置，默认为 cpu。\n",
    "   - requires_grad (bool, optional) – 决定是否需要计算梯度。\n",
    "   - pin_memory (bool, optional) – 是否将tensor存于锁页内存。这与内存的存储方式有关，通常为False\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf179b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.],\n",
      "        [ 2., -2.]]) torch.float32\n",
      "tensor([[ 1., -1.],\n",
      "        [ 2., -2.]]) torch.float32\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32) torch.int32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "l = [[1., -1.], [2., -2.]]\n",
    "t_from_l = torch.tensor(l)\n",
    "t = ((1., -1.), (2., -2.))\n",
    "t_from_t = torch.tensor(t)\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "t_from_arr = torch.tensor(arr)\n",
    "\n",
    "print(t_from_l, t_from_l.dtype)\n",
    "print(t_from_t, t_from_t.dtype)\n",
    "print(t_from_arr, t_from_arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8906d",
   "metadata": {},
   "source": [
    "**torch.from_numpy**\n",
    "\n",
    "还有一种常用的通过numpy创建tensor方法是torch.from_numpy()。这里需要特别注意的是，**创建的tensor和原array共享同一块内存（The returned tensor and ndarray share the same memory. ）**，即当改变array里的数值，tensor中的数值也会被改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed0ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy array:  [[1 2 3]\n",
      " [4 5 6]]\n",
      "tensor :  tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "\n",
      "修改arr\n",
      "numpy array:  [[0 2 3]\n",
      " [4 5 6]]\n",
      "tensor :  tensor([[0, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "\n",
      "修改tensor\n",
      "numpy array:  [[-1  2  3]\n",
      " [ 4  5  6]]\n",
      "tensor :  tensor([[-1,  2,  3],\n",
      "        [ 4,  5,  6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "t_from_numpy = torch.from_numpy(arr)\n",
    "print(\"numpy array: \", arr)\n",
    "print(\"tensor : \", t_from_numpy)\n",
    "print(\"\\n修改arr\")\n",
    "arr[0, 0] = 0\n",
    "print(\"numpy array: \", arr)\n",
    "print(\"tensor : \", t_from_numpy)\n",
    "print(\"\\n修改tensor\")\n",
    "t_from_numpy[0, 0] = -1\n",
    "print(\"numpy array: \", arr)\n",
    "print(\"tensor : \", t_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b13307",
   "metadata": {},
   "source": [
    "### 4.2.2 依数值创建\n",
    "\n",
    "\n",
    "**torch.zeros():**\n",
    "\n",
    "`torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "功能：依给定的size创建一个全0的tensor，**默认数据类型为torch.float32（也称为torch.float）**。\n",
    "\n",
    "主要参数：\n",
    "\n",
    "   - layout(torch.layout, optional) - 参数表明张量在内存中采用何种布局方式。常用的有torch.strided, torch.sparse_coo等。\n",
    "\n",
    "   - out(tensor, optional) - 输出的tensor，即该函数返回的tensor可以通过out进行赋值，请看例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dd84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]) \n",
      " tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "2091989478352 2091989478352\n"
     ]
    }
   ],
   "source": [
    "o_t = torch.tensor([1])\n",
    "t = torch.zeros((3,3), out=o_t)\n",
    "print(t, '\\n', o_t)\n",
    "print(id(t), id(o_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c39c9",
   "metadata": {},
   "source": [
    "可以看到，通过out参数的设置将新创建的zero张量赋值给了o_t，两者共享相同的内存.\n",
    "\n",
    "**torch.zeros_like()**\n",
    "\n",
    "`torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False)`\n",
    "\n",
    "功能：依input的size创建全0的tensor。\n",
    "\n",
    "主要参数：\n",
    "\n",
    "input(Tensor) - 创建的tensor与intput具有相同的形状。\n",
    "\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c835b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.],\n",
      "        [ 2., -2.]]) \n",
      " tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1., -1.],[2., -2.]])\n",
    "t2 = torch.zeros_like(t1)\n",
    "\n",
    "print(t1, '\\n', t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99958efc",
   "metadata": {},
   "source": [
    "除了能够创建全0之外，还可以通过`torch.ones()`和`torch.ones_like()`创建全1，用法和创建全0一致。\n",
    "\n",
    "**troch.full()**\n",
    "\n",
    "`torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "功能：依给定的size创建一个值全为fill_value的tensor。\n",
    "\n",
    "主要参数:\n",
    "\n",
    "siz (int...) - tensor的形状。\n",
    "\n",
    "fill_value - 所创建tensor的值\n",
    "\n",
    "out(tensor, optional) - 输出的tensor，即该函数返回的tensor可以通过out进行赋值。\n",
    "\n",
    "**troch.full_like()**\n",
    "\n",
    "`torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7c3328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4000, 2.4000, 2.4000, 2.4000],\n",
      "        [2.4000, 2.4000, 2.4000, 2.4000],\n",
      "        [2.4000, 2.4000, 2.4000, 2.4000]])\n",
      "tensor([[2.5500, 2.5500],\n",
      "        [2.5500, 2.5500]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "full_t = torch.full((3,4), 2.4)\n",
    "t = torch.tensor([[1., -1.], [2., -2.]])\n",
    "full_like_t = torch.full_like(t, 2.55)\n",
    "\n",
    "print(full_t)\n",
    "print(full_like_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fb91e",
   "metadata": {},
   "source": [
    "**torch.arange()**\n",
    "\n",
    "`torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "功能：创建等差的1维张量，长度为 (end-start)/step，需要注意数值区间为[start, end)。\n",
    "\n",
    "主要参数：\n",
    "\n",
    "   - start (Number) – 数列起始值，默认值为0。the starting value for the set of points. Default: 0.\n",
    "   - end (Number) – 数列的结束值。\n",
    "   - step (Number) – 数列的等差值，默认值为1。\n",
    "   - out (Tensor, optional) – 输出的tensor，即该函数返回的tensor可以通过out进行赋值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0afa892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "arange_t = torch.arange(0, 11, 2)\n",
    "print(arange_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e68a28",
   "metadata": {},
   "source": [
    "**torch.linspace()**\n",
    "\n",
    "`torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "功能：创建均分的1维张量，长度为steps，区间为[start, end]。\n",
    "\n",
    "**torch.logspace()**\n",
    "\n",
    "`torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "功能：创建对数均分的1维张量，长度为steps, 底为base。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32d63565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "linspace_t = torch.linspace(0, 10, steps=10)\n",
    "logspace_t = torch.logspace(0, 1, steps=10)\n",
    "\n",
    "plt.scatter(range(0, 10),linspace_t.detach())\n",
    "plt.scatter(range(0, 10), logspace_t.detach())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41832948",
   "metadata": {},
   "source": [
    "**torch.eye()**\n",
    "\n",
    "`torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)**`\n",
    "\n",
    "功能：创建单位对角矩阵。\n",
    "\n",
    "主要参数：\n",
    "\n",
    "n (int) - 矩阵的行数\n",
    "\n",
    "m (int, optional) - 矩阵的列数，默认值为n，即默认创建一个方阵\n",
    "\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b0a3270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.eye(3))\n",
    "print(torch.eye(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42421d",
   "metadata": {},
   "source": [
    "**torch.empty**\n",
    "\n",
    "`torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False)`\n",
    "\n",
    "功能：依size创建“空”张量，这里的“空”指的是不会进行初始化赋值操作。\n",
    "\n",
    "**torch.empty_like()**\n",
    "\n",
    "`torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False)`\n",
    "\n",
    "**torch.empty_strided**\n",
    "\n",
    "`torch.empty_strided(size, stride, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False)`\n",
    "\n",
    "功能: 创建一个具有指定形状、步幅（stride）和数据类型的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "580053fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0938e+34, 1.4111e-42, 0.0000e+00],\n",
      "        [1.8750e+00, 0.0000e+00, 2.0000e+00]])\n",
      "tensor([[2.0931e+34, 1.4111e-42, 4.2039e-45],\n",
      "        [5.6052e-45, 7.0065e-45, 8.4078e-45]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.empty(2, 3))\n",
    "print(torch.empty_strided((2,3), (3,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1d628",
   "metadata": {},
   "source": [
    "### 4.2.3 依概率分布创建\n",
    "\n",
    "**torch.norm()**\n",
    "\n",
    "`torch.normal(mean, std, out=None)`\n",
    "\n",
    "功能：为每一个元素以给定的mean和std用**高斯分布生成随机数**\n",
    "\n",
    "主要参数：\n",
    "\n",
    "mean (Tensor or Float) - 高斯分布的均值，\n",
    "\n",
    "std (Tensor or Float) - 高斯分布的标准差\n",
    "\n",
    "特别注意事项：\n",
    "\n",
    "mean和std的取值分别有2种，共4种组合，不同组合产生的效果也不同，需要注意\n",
    "\n",
    "mean为张量，std为张量，torch.normal(mean, std, out=None)，每个元素从不同的高斯分布采样，分布的均值和标准差由mean和std对应位置元素的值确定；\n",
    "\n",
    "mean为张量，std为标量，torch.normal(mean, std=1.0, out=None)，每个元素采用相同的标准差，不同的均值；\n",
    "\n",
    "mean为标量，std为张量，torch.normal(mean=0.0, std, out=None)， 每个元素采用相同均值，不同标准差；\n",
    "\n",
    "mean为标量，std为标量，torch.normal(mean, std, size, *, out=None) ，从一个高斯分布中生成大小为size的张量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d19a7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), \n",
      "std: tensor([1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "        0.1000]), \n",
      "normal: tensor([2.2586, 2.0777, 4.2399, 5.0085, 5.7588, 5.8595, 6.7206, 8.1392, 8.9401,\n",
      "        9.9177])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mean = torch.arange(1, 11.)\n",
    "std = torch.arange(1, 0, -0.1)\n",
    "normal = torch.normal(mean=mean, std=std)\n",
    "print(\"mean: {}, \\nstd: {}, \\nnormal: {}\".format(mean, std, normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252ba10",
   "metadata": {},
   "source": [
    "**torch.rand()**\n",
    "\n",
    "`torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "功能：在区间[0, 1)上，生成均匀分布。\n",
    "\n",
    "**torch.rand_like()**\n",
    "\n",
    "**torch.rand()**\n",
    "\n",
    "torch.randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n",
    "功能：在区间[low, high)上，生成整数的均匀分布。\n",
    "\n",
    "**torch.randint_like()**\n",
    "\n",
    "**torch.randint_like()**\n",
    "\n",
    "torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n",
    "功能：生成形状为size的标准正态分布张量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c965c7",
   "metadata": {},
   "source": [
    "## 五.张量的操作\n",
    "\n",
    "主要包括拼接（concat，stack），拆分（chunk，split），改变形状（permute，reshape）等操作，具体不仔细列举，使用时具体情况进行分析。\n",
    "\n",
    "| 名称  |  用途  |\n",
    "|:------:|:---------:|\n",
    "|  cat  | 用于向量的特征融合拼接|\n",
    "|  concat  | 向量的按着某一维度特征融合拼接|\n",
    "|  column_stack  | 水平堆叠张量。即第二个维度上增加，等同于torch.hstack。|\n",
    "|  vstack   | 垂直堆叠 |\n",
    "|  stack   | 在新的轴上拼接张量。与hstack\\vstack不同，它是新增一个轴。默认从第0个轴插入新轴。|\n",
    "|  chunk  | 将向量按某一维度进行拆分|\n",
    "|  dsplit  | 类似numpy.dsplit().， 将张量按索引或指定的份数进行切分|\n",
    "|  split  | 按给定的大小切分出多个张量|\n",
    "|  permute  | 交换轴|\n",
    "|  reshape | 改变形状，要求改变前后的两个tensor元素相等|\n",
    "| transpose  | 用于交换张量中的两个维度|\n",
    "|  unsqueeze  | 增加一个轴，常用于匹配数据维度|\n",
    "|  squeeze  | 去除张量中所有（指定维度）大小为1的维度|\n",
    "| nonzero |返回非零的索引|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40da9a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.concat(dim=0):\n",
      " tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "torch.concat(dim=1):\n",
      " tensor([[ 1,  2,  7,  8],\n",
      "        [ 3,  4,  9, 10],\n",
      "        [ 5,  6, 11, 12]])\n",
      "torch.vstack():\n",
      " tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "torch.column_stack():\n",
      " tensor([[ 1,  2,  7,  8],\n",
      "        [ 3,  4,  9, 10],\n",
      "        [ 5,  6, 11, 12]])\n",
      "torch.stack():\n",
      " tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 7,  8],\n",
      "         [ 9, 10],\n",
      "         [11, 12]]])\n",
      "Chunk 1:\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "Chunk 2:\n",
      "tensor([[ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]])\n",
      "Split 1:\n",
      "tensor([[1, 2, 3, 4]])\n",
      "Split 2:\n",
      "tensor([[ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "Split 3:\n",
      "tensor([[13, 14, 15, 16]])\n",
      "torch.permute:\n",
      " tensor([[[ 1, 13],\n",
      "         [ 5, 17],\n",
      "         [ 9, 21]],\n",
      "\n",
      "        [[ 2, 14],\n",
      "         [ 6, 18],\n",
      "         [10, 22]],\n",
      "\n",
      "        [[ 3, 15],\n",
      "         [ 7, 19],\n",
      "         [11, 23]],\n",
      "\n",
      "        [[ 4, 16],\n",
      "         [ 8, 20],\n",
      "         [12, 24]]])\n",
      "torch.transpose:\n",
      " tensor([[[ 1, 13],\n",
      "         [ 5, 17],\n",
      "         [ 9, 21]],\n",
      "\n",
      "        [[ 2, 14],\n",
      "         [ 6, 18],\n",
      "         [10, 22]],\n",
      "\n",
      "        [[ 3, 15],\n",
      "         [ 7, 19],\n",
      "         [11, 23]],\n",
      "\n",
      "        [[ 4, 16],\n",
      "         [ 8, 20],\n",
      "         [12, 24]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_e = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "tensor_f = torch.tensor([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "# 沿着行拼接\n",
    "tensor_concat = torch.concat((tensor_e, tensor_f), dim=0)\n",
    "print(\"torch.concat(dim=0):\\n\", tensor_concat)\n",
    "\n",
    "# 沿着列拼接\n",
    "tensor_concat = torch.concat((tensor_e, tensor_f), dim=1)\n",
    "print(\"torch.concat(dim=1):\\n\", tensor_concat)\n",
    "\n",
    "# 使用 vstack 沿列堆叠\n",
    "result = torch.vstack((tensor_e, tensor_f))\n",
    "\n",
    "print(\"torch.vstack():\\n\", result)\n",
    "\n",
    "# 使用 column_stack 沿列堆叠\n",
    "result = torch.column_stack((tensor_e, tensor_f))\n",
    "\n",
    "print(\"torch.column_stack():\\n\", result)\n",
    "\n",
    "# 使用 stack堆叠\n",
    "result = torch.stack((tensor_e, tensor_f), dim=0)\n",
    "\n",
    "print(\"torch.stack():\\n\", result)\n",
    "\n",
    "# 创建一个4x4的张量\n",
    "tensor = torch.tensor([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8],\n",
    "                       [9, 10, 11, 12],\n",
    "                       [13, 14, 15, 16]])\n",
    "\n",
    "# 将张量沿着第0维（行）分割成两块\n",
    "chunks = torch.chunk(tensor, 2, dim=0)\n",
    "\n",
    "# 输出结果\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\")\n",
    "\n",
    "# 按指定的大小分割：第一个块1行，第二个块2行，第三个块1行\n",
    "split_tensors = torch.split(tensor, [1, 2, 1], dim=0)\n",
    "\n",
    "# 输出结果\n",
    "for i, split_tensor in enumerate(split_tensors):\n",
    "    print(f\"Split {i+1}:\\n{split_tensor}\")\n",
    "    \n",
    "\n",
    "# 创建一个形状为 (2, 3, 4) 的张量\n",
    "x = torch.tensor([[[ 1,  2,  3,  4],\n",
    "                   [ 5,  6,  7,  8],\n",
    "                   [ 9, 10, 11, 12]],\n",
    "\n",
    "                  [[13, 14, 15, 16],\n",
    "                   [17, 18, 19, 20],\n",
    "                   [21, 22, 23, 24]]])\n",
    "y = torch.permute(x, (2, 1, 0))\n",
    "print(\"torch.permute:\\n\",y)\n",
    "y = torch.transpose(x, 0, 2)\n",
    "print(\"torch.transpose:\\n\",y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89fb22",
   "metadata": {},
   "source": [
    "## 五.张量的随机种子\n",
    "\n",
    "随机种子（Random Seed）是一种控制随机数生成器起始状态的机制，给定一个初始状态（即种子），它每次都会生成相同的随机数序列。\n",
    "\n",
    "| | |\n",
    "|------|--------|\n",
    "| seed | 返回一个新的随机种子值，但不会设置全局随机种子 |\n",
    "| manual_seed | 设置全局的随机种子，确保CPU上的随机操作是可重复的，建议设置为42|\n",
    "| initial_seed | 返回初始种子|\n",
    "| get_rng_state | 返回生成器的状态|\n",
    "| set_rng_state | 设置随机数生成器的状态|\n",
    "\n",
    "以上均是设置cpu上的张量随机种子，在cuda上是另外一套随机种子，如torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f11610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前种子值: 48633472717800\n",
      "初始随机种子: 412\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 生成一个新的随机种子\n",
    "seed_value = torch.seed()\n",
    "print(\"当前种子值:\", seed_value)\n",
    "\n",
    "# 设置全局随机种子\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 获取初始随机种子值\n",
    "initial_seed = torch.initial_seed()\n",
    "print(\"初始随机种子:\", initial_seed)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9556436",
   "metadata": {},
   "source": [
    "## 六.张量的数学运算\n",
    "\n",
    "张量还提供大量数学操作，估计了一下，有快一百个函数，这里就不再一一分析，只需要知道有哪几大类，用到的时候来查吧。\n",
    "   - [Pointwise Ops](https://pytorch.org/docs/stable/torch.html#pointwise-ops) 逐元素的操作，如abs, cos, sin, floor, floor_divide, pow等\n",
    "   - [Reduction Ops](https://pytorch.org/docs/stable/torch.html#reduction-ops) 减少元素的操作，如argmax, argmin, all, any, mean, norm, var等\n",
    "   - [Comparison Ops](https://pytorch.org/docs/stable/torch.html#comparison-ops) 对比操作， 如ge, gt, le, lt, eq, argsort, isnan, topk,\n",
    "   - [Spectral Ops](https://pytorch.org/docs/stable/torch.html#pointwise-ops) 谱操作，如短时傅里叶变换等各类信号处理的函数。\n",
    "   - [Other Operations](https://pytorch.org/docs/stable/torch.html#pointwise-ops) 其它， clone， diag，flip等\n",
    "   - [BLAS and LAPACK Operations](https://pytorch.org/docs/stable/torch.html#pointwise-ops) BLAS（Basic Linear Algebra Subprograms）基础线性代数）操作。如, addmm, dot, inner, svd等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e01f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
